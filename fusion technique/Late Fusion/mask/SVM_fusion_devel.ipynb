{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes    = ['clear', 'mask']\n",
    "feature_sets=['_ComParE','BoAW','auDeep','DeepSpectrum_resnet50','FV6','FV_LLD']\n",
    "tuned_parameters = {'gamma': [100,10,1,1e-1,1e-2,1e-3],\n",
    "                    'C': [100,10,1,1e-1,1e-2,1e-3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readcsv(feature):\n",
    "    files=os.listdir()\n",
    "    for file in files:\n",
    "        if feature in file:\n",
    "            return pd.read_csv(file)['prob0'].values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ComParE\n",
      "[0.56543286 0.81283127 0.14612692 ... 0.28267454 0.64667312 0.24305277]\n",
      "BoAW\n",
      "[0.34299999 0.9256225  0.28748837 ... 0.52506372 0.59952203 0.4729858 ]\n",
      "auDeep\n",
      "[0.63642953 0.86604398 0.19370036 ... 0.34671974 0.31651106 0.34988477]\n",
      "DeepSpectrum_resnet50\n",
      "[0.41269561 0.77586207 0.43334282 ... 0.07522409 0.72937518 0.37582475]\n",
      "FV6\n",
      "[0.64576268 0.96587454 0.06827503 ... 0.22243974 0.340786   0.48516783]\n",
      "FV_LLD\n",
      "[7.81021898e-01 1.00000000e+00 9.46969697e-04 ... 9.46969697e-04\n",
      " 9.42982456e-01 8.38323353e-03]\n"
     ]
    }
   ],
   "source": [
    "predlists=[]\n",
    "for i in range(len(feature_sets)):\n",
    "    print(feature_sets[i])\n",
    "    print(readcsv(feature_sets[i]))\n",
    "    predlists.append([])\n",
    "    predlists[-1].append(readcsv(feature_sets[i]))\n",
    "    predlists[-1].append(1-readcsv(feature_sets[i]))\n",
    "label_file    = 'labels.csv'\n",
    "df_labels = pd.read_csv(label_file)\n",
    "y_devel = df_labels['label'][df_labels['file_name'].str.startswith('devel')].values\n",
    "\n",
    "pred=[]\n",
    "for i in range(len(predlists[0][0])):\n",
    "    pred.append([predlists[j][0][i] for j in range(len(predlists))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(feature_sets):\n",
    "    \n",
    "    #[[[0],[1]],[[0],[1]]]\n",
    "    predlists=[]\n",
    "    for i in range(len(feature_sets)):\n",
    "        predlists.append([])\n",
    "        predlists[-1].append(readcsv(feature_sets[i]))\n",
    "        predlists[-1].append(1-readcsv(feature_sets[i]))\n",
    "    label_file    = 'labels.csv'\n",
    "    df_labels = pd.read_csv(label_file)\n",
    "    y_devel = df_labels['label'][df_labels['file_name'].str.startswith('devel')].values\n",
    "    \n",
    "    pred=[]\n",
    "    for i in range(len(predlists[0][0])):\n",
    "        pred.append([predlists[j][0][i] for j in range(len(predlists))])\n",
    "        \n",
    "    uar_scores = []\n",
    "    X_train=pred\n",
    "    print('gamma:\\t',end='')\n",
    "    for g in tuned_parameters['gamma']:\n",
    "        print(g,'\\t',end='')\n",
    "    print('\\nC:')\n",
    "    for comp in tuned_parameters['C']:\n",
    "        print(comp,':\\t',end='')\n",
    "        for g in tuned_parameters['gamma']:\n",
    "            clf = svm.SVC(C=comp,gamma=g)\n",
    "        \n",
    "            #cross validation\n",
    "            kf = KFold(n_splits=5)\n",
    "            uarList=[]\n",
    "            for train_index, test_index in kf.split(X_train):\n",
    "                #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "                clf.fit([X_train[i] for i in train_index], [y_devel[i] for i in train_index])\n",
    "                y_pred = clf.predict([X_train[i] for i in test_index])\n",
    "                uarList.append(recall_score([y_devel[i] for i in test_index], y_pred, labels=classes, average='macro'))\n",
    "                \n",
    "            uar_scores.append(np.mean(uarList))\n",
    "            \n",
    "            print('{0:.3f}'.format(uar_scores[-1]*100),'\\t',end='')\n",
       "        print()\n",
    "\n",
    "\n",
    "    return max(uar_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma:\t100 \t10 \t1 \t0.1 \t0.01 \t0.001 \t\n",
      "C:\n",
      "100 :\t63.1 \t66.1 \t71.2 \t71.1 \t70.3 \t71.3 \t\n",
      "10 :\t63.9 \t68.8 \t71.1 \t71.2 \t71.2 \t71.2 \t\n",
      "1 :\t67.2 \t70.9 \t71.1 \t70.6 \t71.1 \t70.3 \t\n",
      "0.1 :\t52.6 \t71.1 \t71.1 \t70.9 \t70.3 \t50.0 \t\n",
      "0.01 :\t50.0 \t70.9 \t70.9 \t70.3 \t50.0 \t50.0 \t\n",
      "0.001 :\t50.0 \t50.0 \t70.2 \t50.0 \t50.0 \t50.0 \t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7125423556535972"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion(feature_sets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
