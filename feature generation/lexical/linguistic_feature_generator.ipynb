{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import operator\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import math\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"USOMS-e_linguistic_feature_extractor/data/transcripted_text.st1_st2_st3.all.csv\")\n",
    "set_list = [\"train\", \"devel\", \"test\"]\n",
    "label_list = ['L','M','H']\n",
    "for sets in set_list:\n",
    "        locals()['preprocessed_{}'.format(sets)] = [[x for x in i if type(x) is str] for i in pd.read_csv('preprocessed/'+sets+'_preprossed.csv').values.tolist()]\n",
    "    \n",
    "for sets in set_list:\n",
    "    locals()['df_{}'.format(sets)] = df_all[df_all['partition'].isin([sets])]\n",
    "    locals()['V_cat_{}'.format(sets)] = locals()['df_{}'.format(sets)]['V_cat'].values\n",
    "    locals()['A_cat_{}'.format(sets)] = locals()['df_{}'.format(sets)]['A_cat'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['L', 'L', 'H', 'M', 'M', 'M', 'M', 'L', 'M', 'M', 'M', 'H', 'M',\n",
       "       'M', 'H', 'M', 'M', 'H', 'M', 'L', 'M', 'L', 'M', 'M', 'L', 'L',\n",
       "       'H', 'L', 'M', 'H', 'M', 'M', 'H', 'M', 'L', 'H', 'L', 'L', 'H',\n",
       "       'L', 'L', 'H', 'L', 'L', 'H', 'H', 'M', 'H', 'L', 'L', 'M', 'M',\n",
       "       'M', 'H', 'L', 'M', 'H', 'L', 'L', 'H', 'L', 'L', 'H', 'M', 'L',\n",
       "       'H', 'L', 'M', 'H', 'M', 'M', 'H', 'L', 'L', 'H', 'L', 'L', 'H',\n",
       "       'L', 'L', 'M', 'L', 'M', 'H', 'L', 'L', 'H'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_cat_traindevel = np.insert(V_cat_train,0, V_cat_devel)\n",
    "A_cat_traindevel = np.insert(A_cat_train,0, A_cat_devel)\n",
    "\n",
    "train_cat = [V_cat_train,A_cat_train]\n",
    "traindevel_cat = [V_cat_traindevel,A_cat_traindevel]\n",
    "\n",
    "V_cat_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_traindevel= preprocessed_train + preprocessed_devel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {str(preprocessed_train):'train',str(preprocessed_devel):'devel',str(preprocessed_test):'test',str(preprocessed_traindevel):'traindevel'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate Unique Word List\n",
    "flat = lambda t: [x for sub in t for x in flat(sub)] if isinstance(t, Iterable) else [t]\n",
    "train_only_term_list = [i for i in sorted(list(set(reduce(operator.add,preprocessed_train)))) if (i != '-' and i != \"’s\")]\n",
    "train_devel_term_list = preprocessed_train + preprocessed_devel\n",
    "train_devel_term_list = [i for i in sorted(list(set(reduce(operator.add,train_devel_term_list)))) if (i != '-' and i != \"’s\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2836"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_only_term_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4428"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_devel_term_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2836"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uniques_word_list = train_devel_term_list\n",
    "uniques_word_list = train_only_term_list\n",
    "# print(len(uniques_word_list))\n",
    "len(uniques_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoW(input_set):\n",
    "    story_count_list = []\n",
    "    for story in input_set:\n",
    "        count_list = []\n",
    "        for term in uniques_word_list:\n",
    "            count_list.append(story.count(term))\n",
    "        story_count_list.append(count_list)\n",
    "    BoW =  pd.DataFrame(story_count_list,columns = uniques_word_list,index = None)\n",
    "    if input_set != preprocessed_traindevel:\n",
    "        BoW.to_csv('ComParE2020_USOMS-e.BoW.V_cat_no.'+input_dict[str(input_set)]+'.csv',index = 0)\n",
    "        BoW.to_csv('ComParE2020_USOMS-e.BoW.A_cat_no.'+input_dict[str(input_set)]+'.csv',index = 0)\n",
    "    else:\n",
    "        BoW[0:87].to_csv('ComParE2020_USOMS-e.BoW.V_cat_no.'+'train'+'.csv',index = 0)\n",
    "        BoW[87:175].to_csv('ComParE2020_USOMS-e.BoW.V_cat_no.'+'devel'+'.csv',index = 0)\n",
    "        BoW[0:87].to_csv('ComParE2020_USOMS-e.BoW.A_cat_no.'+'train'+'.csv',index = 0)\n",
    "        BoW[87:175].to_csv('ComParE2020_USOMS-e.BoW.A_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    return BoW\n",
    "# BoW(preprocessed_devel)\n",
    "# BoW(preprocessed_test)\n",
    "\n",
    "\n",
    "def BoW_3(input_set):\n",
    "    story_count_list = []\n",
    "    for story in input_set:\n",
    "        count_list = []\n",
    "        for term in uniques_word_list:\n",
    "            if story.count(term) > 3:\n",
    "                count_list.append(story.count(term))\n",
    "            else:\n",
    "                count_list.append(0)\n",
    "        story_count_list.append(count_list)\n",
    "    BoW =  pd.DataFrame(story_count_list,columns = uniques_word_list,index = None)\n",
    "    if input_set != preprocessed_traindevel:\n",
    "        BoW.to_csv('ComParE2020_USOMS-e.BoW_3.V_cat_no.'+input_dict[str(input_set)]+'.csv',index = 0)\n",
    "        BoW.to_csv('ComParE2020_USOMS-e.BoW_3.A_cat_no.'+input_dict[str(input_set)]+'.csv',index = 0)\n",
    "    else:\n",
    "        BoW[0:87].to_csv('ComParE2020_USOMS-e.BoW_3.V_cat_no.'+'train'+'.csv',index = 0)\n",
    "        BoW[87:175].to_csv('ComParE2020_USOMS-e.BoW_3.V_cat_no.'+'devel'+'.csv',index = 0)\n",
    "        BoW[0:87].to_csv('ComParE2020_USOMS-e.BoW_3.A_cat_no.'+'train'+'.csv',index = 0)\n",
    "        BoW[87:175].to_csv('ComParE2020_USOMS-e.BoW_3.A_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    return BoW\n",
    "\n",
    "# BoW_3(preprocessed_train)\n",
    "# BoW_3(preprocessed_devel)\n",
    "# BoW_3(preprocessed_test)\n",
    "\n",
    "def TF_IDF(input_set):\n",
    "    vectorizer = CountVectorizer(vocabulary=uniques_word_list)\n",
    "    preprossed_story_list = []\n",
    "    for i in input_set:\n",
    "        preprossed_story_list.append(' '.join(i))\n",
    "    X = vectorizer.fit_transform(preprossed_story_list)  \n",
    "    word = vectorizer.get_feature_names()  \n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf = transformer.fit_transform(X)\n",
    "    TF_IDF = pd.DataFrame(tfidf.toarray(),columns = uniques_word_list,index = None)\n",
    "    if input_set != preprocessed_traindevel:\n",
    "        TF_IDF.to_csv('ComParE2020_USOMS-e.TF_IDF.V_cat_no.'+input_dict[str(input_set)]+'.csv',index = 0)\n",
    "        TF_IDF.to_csv('ComParE2020_USOMS-e.TF_IDF.A_cat_no.'+input_dict[str(input_set)]+'.csv',index = 0)\n",
    "    else:\n",
    "        TF_IDF[0:87].to_csv('ComParE2020_USOMS-e.TF_IDF.V_cat_no.'+'train'+'.csv',index = 0)\n",
    "        TF_IDF[87:175].to_csv('ComParE2020_USOMS-e.TF_IDF.V_cat_no.'+'devel'+'.csv',index = 0)\n",
    "        TF_IDF[0:87].to_csv('ComParE2020_USOMS-e.TF_IDF.A_cat_no.'+'train'+'.csv',index = 0)\n",
    "        TF_IDF[87:175].to_csv('ComParE2020_USOMS-e.TF_IDF.A_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    return TF_IDF\n",
    "\n",
    "# TF_IDF(preprocessed_train)\n",
    "# TF_IDF(preprocessed_devel)\n",
    "\n",
    "# TF_IDF(preprocessed_traindevel)\n",
    "# TF_IDF(preprocessed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PMI_WL(input_set):\n",
    "#     if input_set == preprocessed_train:\n",
    "#         cat = train_cat\n",
    "#     elif input_set == preprocessed_traindevel:\n",
    "#         cat = traindevel_cat\n",
    "#     PMI_list = [] # [[V[LMH]],[A[LMH]]]\n",
    "#     for V_A in cat:\n",
    "#         PMI_label_list = []\n",
    "#         for label in label_list:\n",
    "#             PMI_temp_list = []\n",
    "#             for term in uniques_word_list:\n",
    "#                 p_label =  Counter(V_A)[label]/len(V_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_word_train = []\n",
    "# for i in preprocessed_train:\n",
    "#     all_word_train.extend(i)\n",
    "# word_count_for_story = []\n",
    "# for i in preprocessed_train:\n",
    "#     word_count_for_story.append(len(i))\n",
    "\n",
    "# V_cat_train_temp = np.array(V_cat_train)\n",
    "# index_L = np.where(V_cat_train_temp=='L')\n",
    "# index_M = np.where(V_cat_train_temp=='M')\n",
    "# index_H = np.where(V_cat_train_temp=='H')\n",
    "# #     print(index)\n",
    "# # word_count_for_story\n",
    "# L_times = 0\n",
    "# M_times = 0\n",
    "# H_times = 0\n",
    "# for i in index_L[0]:\n",
    "#     L_times += word_count_for_story[i]\n",
    "# for i in index_M[0]:\n",
    "#     M_times += word_count_for_story[i]\n",
    "# for i in index_H[0]:\n",
    "#     H_times += word_count_for_story[i]\n",
    "# times_dict = {'L':L_times,'M':M_times,'H':H_times}\n",
    "# Counter(all_word_train)['jahren']\n",
    "# L_word_list = []\n",
    "# for i in index_L[0]:\n",
    "#     L_word_list.extend(preprocessed_train[i])\n",
    "# M_word_list = []\n",
    "# for i in index_L[0]:\n",
    "#     M_word_list.extend(preprocessed_train[i])\n",
    "# H_word_list = []\n",
    "# for i in index_L[0]:\n",
    "#     H_word_list.extend(preprocessed_train[i])\n",
    "# label_word_dict = {'L':L_word_list,'M':M_word_list,'H':H_word_list}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Counter(L_word_list)\n",
    "# print(all_word_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PMI_SL(input_set):\n",
    "    \n",
    "    if input_set == preprocessed_train:\n",
    "        cat = train_cat\n",
    "    elif input_set == preprocessed_traindevel:\n",
    "        cat = traindevel_cat\n",
    "    PMI_list = [] # [[V[LMH]],[A[LMH]]]\n",
    "    for V_A in cat:\n",
    "        PMI_label_list = []\n",
    "        for label in label_list:\n",
    "            PMI_temp_list = []\n",
    "            for term in uniques_word_list:\n",
    "                \n",
    "                all_word_train = []\n",
    "                for i in input_set:\n",
    "                    all_word_train.extend(i)\n",
    "                word_count_for_story = []\n",
    "                for i in input_set:\n",
    "                    word_count_for_story.append(len(i))\n",
    "\n",
    "                V_cat_train_temp = np.array(V_A)\n",
    "                index_L = np.where(V_cat_train_temp=='L')\n",
    "                index_M = np.where(V_cat_train_temp=='M')\n",
    "                index_H = np.where(V_cat_train_temp=='H')\n",
    "                #     print(index)\n",
    "                # word_count_for_story\n",
    "                L_times = 0\n",
    "                M_times = 0\n",
    "                H_times = 0\n",
    "                for i in index_L[0]:\n",
    "                    L_times += word_count_for_story[i]\n",
    "                for i in index_M[0]:\n",
    "                    M_times += word_count_for_story[i]\n",
    "                for i in index_H[0]:\n",
    "                    H_times += word_count_for_story[i]\n",
    "                times_dict = {'L':L_times,'M':M_times,'H':H_times}\n",
    "                Counter(all_word_train)['jahren']\n",
    "                L_word_list = []\n",
    "                for i in index_L[0]:\n",
    "                    L_word_list.extend(input_set[i])\n",
    "                M_word_list = []\n",
    "                for i in index_L[0]:\n",
    "                    M_word_list.extend(input_set[i])\n",
    "                H_word_list = []\n",
    "                for i in index_L[0]:\n",
    "                    H_word_list.extend(input_set[i])\n",
    "                label_word_dict = {'L':L_word_list,'M':M_word_list,'H':H_word_list}\n",
    "                \n",
    "                \n",
    "#                 p_label =  Counter(V_A)[label]/len(all_word_train)\n",
    "                p_label = times_dict[label]/len(all_word_train)\n",
    "#                 BoW_ = BoW(input_set)\n",
    "#                 word_appear_times = len(input_set)-BoW_[term].value_counts()[0]\n",
    "                word_appear_times = Counter(all_word_train)[term]\n",
    "                if term in label_word_dict[label]:\n",
    "                    label_with_word = Counter(label_word_dict[label])[term]\n",
    "                else:\n",
    "                    label_with_word = 0\n",
    "                if label_with_word != 0:\n",
    "                    p_word_with_label = label_with_word/word_appear_times\n",
    "                    PMI = math.log((p_word_with_label/p_label))\n",
    "                else:\n",
    "                    PMI = 0\n",
    "                print(p_word_with_label,p_label,PMI)\n",
    "                PMI_temp_list.append(PMI)\n",
    "            PMI_label_list.append(PMI_temp_list)\n",
    "        PMI_list.append(PMI_label_list)\n",
    "    PMI_df_V = pd.DataFrame(PMI_list[0])\n",
    "    PMI_df_A = pd.DataFrame(PMI_list[1])\n",
    "    PMI_df_V.to_csv('PMI_V_'+input_dict[str(input_set)]+'.csv')\n",
    "    PMI_df_A.to_csv('PMI_A_'+input_dict[str(input_set)]+'.csv')\n",
    "    print('done')\n",
    "    return PMI_list\n",
    "# PMI_SL(preprocessed_train)\n",
    "# PMI_SL(preprocessed_traindevel)\n",
    "\n",
    "def NGD(input_set):\n",
    "    \n",
    "    if input_set == preprocessed_train:\n",
    "        cat = train_cat\n",
    "    elif input_set == preprocessed_traindevel:\n",
    "        cat = traindevel_cat\n",
    "    PMI_list = [] # [[V[LMH]],[A[LMH]]]\n",
    "    for V_A in cat:\n",
    "        PMI_label_list = []\n",
    "        for label in label_list:\n",
    "            PMI_temp_list = []\n",
    "            for term in uniques_word_list:\n",
    "                \n",
    "                all_word_train = []\n",
    "                for i in input_set:\n",
    "                    all_word_train.extend(i)\n",
    "                word_count_for_story = []\n",
    "                for i in input_set:\n",
    "                    word_count_for_story.append(len(i))\n",
    "\n",
    "                V_cat_train_temp = np.array(V_A)\n",
    "                index_L = np.where(V_cat_train_temp=='L')\n",
    "                index_M = np.where(V_cat_train_temp=='M')\n",
    "                index_H = np.where(V_cat_train_temp=='H')\n",
    "                #     print(index)\n",
    "                # word_count_for_story\n",
    "                L_times = 0\n",
    "                M_times = 0\n",
    "                H_times = 0\n",
    "                for i in index_L[0]:\n",
    "                    L_times += word_count_for_story[i]\n",
    "                for i in index_M[0]:\n",
    "                    M_times += word_count_for_story[i]\n",
    "                for i in index_H[0]:\n",
    "                    H_times += word_count_for_story[i]\n",
    "                times_dict = {'L':L_times,'M':M_times,'H':H_times}\n",
    "                Counter(all_word_train)['jahren']\n",
    "                L_word_list = []\n",
    "                for i in index_L[0]:\n",
    "                    L_word_list.extend(input_set[i])\n",
    "                M_word_list = []\n",
    "                for i in index_L[0]:\n",
    "                    M_word_list.extend(input_set[i])\n",
    "                H_word_list = []\n",
    "                for i in index_L[0]:\n",
    "                    H_word_list.extend(input_set[i])\n",
    "                label_word_dict = {'L':L_word_list,'M':M_word_list,'H':H_word_list}\n",
    "                \n",
    "                word_appear_times = Counter(all_word_train)[term]                \n",
    "#                 p_label =  Counter(V_A)[label]/len(all_word_train)\n",
    "                p_down = math.log(len(all_word_train))-min(math.log(times_dict[label]),math.log(word_appear_times))\n",
    "#                 BoW_ = BoW(input_set)\n",
    "#                 word_appear_times = len(input_set)-BoW_[term].value_counts()[0]\n",
    "                if term in label_word_dict[label]:\n",
    "                    label_with_word = Counter(label_word_dict[label])[term]\n",
    "                else:\n",
    "                    label_with_word = 0\n",
    "                if label_with_word != 0:\n",
    "                    p_up = max(math.log(times_dict[label]),math.log(word_appear_times))-math.log(label_with_word)\n",
    "                    PMI = p_up/p_down\n",
    "                else:\n",
    "                    PMI = 0\n",
    "                print(p_up,p_down,PMI)\n",
    "                PMI_temp_list.append(PMI)\n",
    "            PMI_label_list.append(PMI_temp_list)\n",
    "        PMI_list.append(PMI_label_list)\n",
    "    PMI_df_V = pd.DataFrame(PMI_list[0])\n",
    "    PMI_df_A = pd.DataFrame(PMI_list[1])\n",
    "    PMI_df_V.to_csv('NGD_V_'+input_dict[str(input_set)]+'.csv')\n",
    "    PMI_df_A.to_csv('NGD_A_'+input_dict[str(input_set)]+'.csv')\n",
    "    print('done')\n",
    "    return PMI_list\n",
    "# NGD(preprocessed_train)\n",
    "# NGD(preprocessed_traindevel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "NGD_V_table = pd.read_csv('NGD_V_'+'train'+'.csv',index_col=0)\n",
    "NGD_A_table = pd.read_csv('NGD_A_'+'train'+'.csv',index_col=0)\n",
    "\n",
    "# NGD_V_table.columns = uniques_word_list\n",
    "# NGD_A_table.columns = uniques_word_list\n",
    "# NGD_V_table.index = label_list\n",
    "# NGD_A_table.index = label_list\n",
    "\n",
    "NGD_V_L_list = list(NGD_V_table.loc[0].values)\n",
    "NGD_V_M_list = list(NGD_V_table.loc[1].values)\n",
    "NGD_V_H_list = list(NGD_V_table.loc[2].values)\n",
    "\n",
    "NGD_V_L = dict(zip(uniques_word_list,NGD_V_L_list))\n",
    "NGD_V_M = dict(zip(uniques_word_list,NGD_V_M_list))\n",
    "NGD_V_H = dict(zip(uniques_word_list,NGD_V_H_list))\n",
    "\n",
    "sorted_NGD_V_L = sorted(NGD_V_L.items(),key = operator.itemgetter(1),reverse=True)\n",
    "sorted_NGD_V_M = sorted(NGD_V_M.items(),key = operator.itemgetter(1),reverse=True)\n",
    "sorted_NGD_V_H = sorted(NGD_V_H.items(),key = operator.itemgetter(1),reverse=True)\n",
    "\n",
    "\n",
    "NGD_A_L_list = list(NGD_A_table.loc[0].values)\n",
    "NGD_A_M_list = list(NGD_A_table.loc[1].values)\n",
    "NGD_A_H_list = list(NGD_A_table.loc[2].values)\n",
    "\n",
    "NGD_A_L = dict(zip(uniques_word_list,NGD_A_L_list))\n",
    "NGD_A_M = dict(zip(uniques_word_list,NGD_A_M_list))\n",
    "NGD_A_H = dict(zip(uniques_word_list,NGD_A_H_list))\n",
    "\n",
    "sorted_NGD_A_L = sorted(NGD_A_L.items(),key = operator.itemgetter(1),reverse=True)\n",
    "sorted_NGD_A_M = sorted(NGD_A_M.items(),key = operator.itemgetter(1),reverse=True)\n",
    "sorted_NGD_A_H = sorted(NGD_A_H.items(),key = operator.itemgetter(1),reverse=True)\n",
    "\n",
    "TF_IDF_V_train = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.V_cat_no.train.csv')\n",
    "TF_IDF_V_devel = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.V_cat_no.devel.csv')\n",
    "TF_IDF_V_test = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.V_cat_no.test.csv')\n",
    "\n",
    "TF_IDF_A_train = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.A_cat_no.train.csv')\n",
    "TF_IDF_A_devel = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.A_cat_no.devel.csv')\n",
    "TF_IDF_A_test = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.A_cat_no.test.csv')\n",
    "\n",
    "BoW_V_train = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.V_cat_no.train.csv')\n",
    "BoW_V_devel = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.V_cat_no.devel.csv')\n",
    "BoW_V_test = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.V_cat_no.test.csv')\n",
    "\n",
    "BoW_A_train = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.A_cat_no.train.csv')\n",
    "BoW_A_devel = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.A_cat_no.devel.csv')\n",
    "BoW_A_test = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.A_cat_no.test.csv')\n",
    "\n",
    "number = [800,1000,1200,1500,1800]\n",
    "# number = [1000]\n",
    "\n",
    "for nums in number:\n",
    "    V_L_base = sorted_NGD_V_L[0:nums]\n",
    "    V_M_base = sorted_NGD_V_M[0:nums]\n",
    "    V_H_base = sorted_NGD_V_H[0:nums]\n",
    "    V_L_base_word = [i[0] for i in V_L_base]\n",
    "    V_L_base_value = [i[1] for i in V_L_base]\n",
    "    V_M_base_word = [i[0] for i in V_M_base]\n",
    "    V_M_base_value = [i[1] for i in V_M_base]\n",
    "    V_H_base_word = [i[0] for i in V_H_base]\n",
    "    V_H_base_value = [i[1] for i in V_H_base]\n",
    "    V_base_value = V_L_base_value+V_M_base_value+V_H_base_value\n",
    "    V_base_word = V_L_base_word+V_M_base_word+V_H_base_word\n",
    "    \n",
    "    A_L_base = sorted_NGD_A_L[0:nums]\n",
    "    A_M_base = sorted_NGD_A_M[0:nums]\n",
    "    A_H_base = sorted_NGD_A_H[0:nums]\n",
    "    A_L_base_word = [i[0] for i in A_L_base]\n",
    "    A_L_base_value = [i[1] for i in A_L_base]\n",
    "    A_M_base_word = [i[0] for i in A_M_base]\n",
    "    A_M_base_value = [i[1] for i in A_M_base]\n",
    "    A_H_base_word = [i[0] for i in A_H_base]\n",
    "    A_H_base_value = [i[1] for i in A_H_base]\n",
    "    A_base_value = A_L_base_value+A_M_base_value+A_H_base_value\n",
    "    A_base_word = A_L_base_word+A_M_base_word+A_H_base_word\n",
    "\n",
    "\n",
    "    NGD_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_train)))\n",
    "    NGD_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_train)))\n",
    "    for story_index in NGD_V_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(V_base_word)):\n",
    "            NGD_V_base.iloc[story_index,term_index] = NGD_V_base.iloc[story_index,term_index]* TF_IDF_V_train.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "    for story_index in NGD_A_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(A_base_word)):\n",
    "            NGD_A_base.iloc[story_index,term_index] = NGD_A_base.iloc[story_index,term_index]* TF_IDF_A_train.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "    NGD_V_base.to_csv('ComParE2020_USOMS-e.NGD_base_TF_IDF_'+str(nums)+'.V_cat_no.'+'train'+'.csv',index = 0)\n",
    "    NGD_A_base.to_csv('ComParE2020_USOMS-e.NGD_base_TF_IDF_'+str(nums)+'.A_cat_no.'+'train'+'.csv',index = 0)\n",
    "    \n",
    "    \n",
    "    NGD_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_devel)))\n",
    "    NGD_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_devel)))\n",
    "    for story_index in NGD_V_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(V_base_word)):\n",
    "            NGD_V_base.iloc[story_index,term_index] = NGD_V_base.iloc[story_index,term_index]* TF_IDF_V_devel.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "    for story_index in NGD_A_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(A_base_word)):\n",
    "            NGD_A_base.iloc[story_index,term_index] = NGD_A_base.iloc[story_index,term_index]* TF_IDF_A_devel.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "    NGD_V_base.to_csv('ComParE2020_USOMS-e.NGD_base_TF_IDF_'+str(nums)+'.V_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    NGD_A_base.to_csv('ComParE2020_USOMS-e.NGD_base_TF_IDF_'+str(nums)+'.A_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    \n",
    "    \n",
    "    NGD_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_test)))\n",
    "    NGD_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_test)))\n",
    "    for story_index in NGD_V_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(V_base_word)):\n",
    "            NGD_V_base.iloc[story_index,term_index] = NGD_V_base.iloc[story_index,term_index]* TF_IDF_V_test.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "    for story_index in NGD_A_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(A_base_word)):\n",
    "            NGD_A_base.iloc[story_index,term_index] = NGD_A_base.iloc[story_index,term_index]* TF_IDF_A_test.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "    NGD_V_base.to_csv('ComParE2020_USOMS-e.NGD_base_TF_IDF_'+str(nums)+'.V_cat_no.'+'test'+'.csv',index = 0)\n",
    "    NGD_A_base.to_csv('ComParE2020_USOMS-e.NGD_base_TF_IDF_'+str(nums)+'.A_cat_no.'+'test'+'.csv',index = 0)\n",
    "\n",
    "\n",
    "\n",
    "    NGD_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_train)))\n",
    "    NGD_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_train)))\n",
    "    for story_index in NGD_V_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(V_base_word)):\n",
    "            NGD_V_base.iloc[story_index,term_index] = NGD_V_base.iloc[story_index,term_index]* BoW_V_train.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "    for story_index in NGD_A_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(A_base_word)):\n",
    "            NGD_A_base.iloc[story_index,term_index] = NGD_A_base.iloc[story_index,term_index]* BoW_A_train.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "    NGD_V_base.to_csv('ComParE2020_USOMS-e.NGD_base_BoW_'+str(nums)+'.V_cat_no.'+'train'+'.csv',index = 0)\n",
    "    NGD_A_base.to_csv('ComParE2020_USOMS-e.NGD_base_BoW_'+str(nums)+'.A_cat_no.'+'train'+'.csv',index = 0)\n",
    "    \n",
    "    \n",
    "    NGD_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_devel)))\n",
    "    NGD_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_devel)))\n",
    "    for story_index in NGD_V_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(V_base_word)):\n",
    "            NGD_V_base.iloc[story_index,term_index] = NGD_V_base.iloc[story_index,term_index]* BoW_V_devel.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "    for story_index in NGD_A_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(A_base_word)):\n",
    "            NGD_A_base.iloc[story_index,term_index] = NGD_A_base.iloc[story_index,term_index]* BoW_A_devel.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "    NGD_V_base.to_csv('ComParE2020_USOMS-e.NGD_base_BoW_'+str(nums)+'.V_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    NGD_A_base.to_csv('ComParE2020_USOMS-e.NGD_base_BoW_'+str(nums)+'.A_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    \n",
    "    \n",
    "    NGD_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_test)))\n",
    "    NGD_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_test)))\n",
    "    for story_index in NGD_V_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(V_base_word)):\n",
    "            NGD_V_base.iloc[story_index,term_index] = NGD_V_base.iloc[story_index,term_index]* BoW_V_test.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "    for story_index in NGD_A_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(A_base_word)):\n",
    "            NGD_A_base.iloc[story_index,term_index] = NGD_A_base.iloc[story_index,term_index]* BoW_A_test.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "    NGD_V_base.to_csv('ComParE2020_USOMS-e.NGD_base_BoW_'+str(nums)+'.V_cat_no.'+'test'+'.csv',index = 0)\n",
    "    NGD_A_base.to_csv('ComParE2020_USOMS-e.NGD_base_BoW_'+str(nums)+'.A_cat_no.'+'test'+'.csv',index = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Done')\n",
    "print('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "PMI_V_table = pd.read_csv('PMI_V_'+'train'+'.csv',index_col=0)\n",
    "PMI_A_table = pd.read_csv('PMI_A_'+'train'+'.csv',index_col=0)\n",
    "\n",
    "# PMI_V_table.columns = uniques_word_list\n",
    "# PMI_A_table.columns = uniques_word_list\n",
    "# PMI_V_table.index = label_list\n",
    "# PMI_A_table.index = label_list\n",
    "\n",
    "PMI_V_L_list = list(PMI_V_table.loc[0].values)\n",
    "PMI_V_M_list = list(PMI_V_table.loc[1].values)\n",
    "PMI_V_H_list = list(PMI_V_table.loc[2].values)\n",
    "\n",
    "PMI_V_L = dict(zip(uniques_word_list,PMI_V_L_list))\n",
    "PMI_V_M = dict(zip(uniques_word_list,PMI_V_M_list))\n",
    "PMI_V_H = dict(zip(uniques_word_list,PMI_V_H_list))\n",
    "\n",
    "sorted_PMI_V_L = sorted(PMI_V_L.items(),key = operator.itemgetter(1),reverse=True)\n",
    "sorted_PMI_V_M = sorted(PMI_V_M.items(),key = operator.itemgetter(1),reverse=True)\n",
    "sorted_PMI_V_H = sorted(PMI_V_H.items(),key = operator.itemgetter(1),reverse=True)\n",
    "\n",
    "\n",
    "PMI_A_L_list = list(PMI_A_table.loc[0].values)\n",
    "PMI_A_M_list = list(PMI_A_table.loc[1].values)\n",
    "PMI_A_H_list = list(PMI_A_table.loc[2].values)\n",
    "\n",
    "PMI_A_L = dict(zip(uniques_word_list,PMI_A_L_list))\n",
    "PMI_A_M = dict(zip(uniques_word_list,PMI_A_M_list))\n",
    "PMI_A_H = dict(zip(uniques_word_list,PMI_A_H_list))\n",
    "\n",
    "sorted_PMI_A_L = sorted(PMI_A_L.items(),key = operator.itemgetter(1),reverse=True)\n",
    "sorted_PMI_A_M = sorted(PMI_A_M.items(),key = operator.itemgetter(1),reverse=True)\n",
    "sorted_PMI_A_H = sorted(PMI_A_H.items(),key = operator.itemgetter(1),reverse=True)\n",
    "\n",
    "TF_IDF_V_train = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.V_cat_no.train.csv')\n",
    "TF_IDF_V_devel = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.V_cat_no.devel.csv')\n",
    "TF_IDF_V_test = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.V_cat_no.test.csv')\n",
    "\n",
    "TF_IDF_A_train = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.A_cat_no.train.csv')\n",
    "TF_IDF_A_devel = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.A_cat_no.devel.csv')\n",
    "TF_IDF_A_test = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.A_cat_no.test.csv')\n",
    "\n",
    "BoW_V_train = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.V_cat_no.train.csv')\n",
    "BoW_V_devel = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.V_cat_no.devel.csv')\n",
    "BoW_V_test = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.V_cat_no.test.csv')\n",
    "\n",
    "BoW_A_train = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.A_cat_no.train.csv')\n",
    "BoW_A_devel = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.A_cat_no.devel.csv')\n",
    "BoW_A_test = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.A_cat_no.test.csv')\n",
    "\n",
    "number = [800,1000,1200,1500,1800]\n",
    "# number = [1000]\n",
    "\n",
    "for nums in number:\n",
    "    V_L_base = sorted_PMI_V_L[0:nums]\n",
    "    V_M_base = sorted_PMI_V_M[0:nums]\n",
    "    V_H_base = sorted_PMI_V_H[0:nums]\n",
    "    V_L_base_word = [i[0] for i in V_L_base]\n",
    "    V_L_base_value = [i[1] for i in V_L_base]\n",
    "    V_M_base_word = [i[0] for i in V_M_base]\n",
    "    V_M_base_value = [i[1] for i in V_M_base]\n",
    "    V_H_base_word = [i[0] for i in V_H_base]\n",
    "    V_H_base_value = [i[1] for i in V_H_base]\n",
    "    V_base_value = V_L_base_value+V_M_base_value+V_H_base_value\n",
    "    V_base_word = V_L_base_word+V_M_base_word+V_H_base_word\n",
    "    \n",
    "    A_L_base = sorted_PMI_A_L[0:nums]\n",
    "    A_M_base = sorted_PMI_A_M[0:nums]\n",
    "    A_H_base = sorted_PMI_A_H[0:nums]\n",
    "    A_L_base_word = [i[0] for i in A_L_base]\n",
    "    A_L_base_value = [i[1] for i in A_L_base]\n",
    "    A_M_base_word = [i[0] for i in A_M_base]\n",
    "    A_M_base_value = [i[1] for i in A_M_base]\n",
    "    A_H_base_word = [i[0] for i in A_H_base]\n",
    "    A_H_base_value = [i[1] for i in A_H_base]\n",
    "    A_base_value = A_L_base_value+A_M_base_value+A_H_base_value\n",
    "    A_base_word = A_L_base_word+A_M_base_word+A_H_base_word\n",
    "\n",
    "\n",
    "    PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_train)))\n",
    "    PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_train)))\n",
    "    for story_index in PMI_V_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(V_base_word)):\n",
    "            PMI_V_base.iloc[story_index,term_index] = PMI_V_base.iloc[story_index,term_index]* TF_IDF_V_train.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "    for story_index in PMI_A_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(A_base_word)):\n",
    "            PMI_A_base.iloc[story_index,term_index] = PMI_A_base.iloc[story_index,term_index]* TF_IDF_A_train.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "    PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.V_cat_no.'+'train'+'.csv',index = 0)\n",
    "    PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.A_cat_no.'+'train'+'.csv',index = 0)\n",
    "    \n",
    "    \n",
    "    PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_devel)))\n",
    "    PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_devel)))\n",
    "    for story_index in PMI_V_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(V_base_word)):\n",
    "            PMI_V_base.iloc[story_index,term_index] = PMI_V_base.iloc[story_index,term_index]* TF_IDF_V_devel.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "    for story_index in PMI_A_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(A_base_word)):\n",
    "            PMI_A_base.iloc[story_index,term_index] = PMI_A_base.iloc[story_index,term_index]* TF_IDF_A_devel.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "    PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.V_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.A_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    \n",
    "    \n",
    "    PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_test)))\n",
    "    PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_test)))\n",
    "    for story_index in PMI_V_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(V_base_word)):\n",
    "            PMI_V_base.iloc[story_index,term_index] = PMI_V_base.iloc[story_index,term_index]* TF_IDF_V_test.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "    for story_index in PMI_A_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(A_base_word)):\n",
    "            PMI_A_base.iloc[story_index,term_index] = PMI_A_base.iloc[story_index,term_index]* TF_IDF_A_test.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "    PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.V_cat_no.'+'test'+'.csv',index = 0)\n",
    "    PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.A_cat_no.'+'test'+'.csv',index = 0)\n",
    "\n",
    "\n",
    "\n",
    "    PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_train)))\n",
    "    PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_train)))\n",
    "    for story_index in PMI_V_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(V_base_word)):\n",
    "            PMI_V_base.iloc[story_index,term_index] = PMI_V_base.iloc[story_index,term_index]* BoW_V_train.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "    for story_index in PMI_A_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(A_base_word)):\n",
    "            PMI_A_base.iloc[story_index,term_index] = PMI_A_base.iloc[story_index,term_index]* BoW_A_train.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "    PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_BoW_'+str(nums)+'.V_cat_no.'+'train'+'.csv',index = 0)\n",
    "    PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_BoW_'+str(nums)+'.A_cat_no.'+'train'+'.csv',index = 0)\n",
    "    \n",
    "    \n",
    "    PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_devel)))\n",
    "    PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_devel)))\n",
    "    for story_index in PMI_V_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(V_base_word)):\n",
    "            PMI_V_base.iloc[story_index,term_index] = PMI_V_base.iloc[story_index,term_index]* BoW_V_devel.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "    for story_index in PMI_A_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(A_base_word)):\n",
    "            PMI_A_base.iloc[story_index,term_index] = PMI_A_base.iloc[story_index,term_index]* BoW_A_devel.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "    PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_BoW_'+str(nums)+'.V_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_BoW_'+str(nums)+'.A_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    \n",
    "    \n",
    "    PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_test)))\n",
    "    PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_test)))\n",
    "    for story_index in PMI_V_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(V_base_word)):\n",
    "            PMI_V_base.iloc[story_index,term_index] = PMI_V_base.iloc[story_index,term_index]* BoW_V_test.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "    for story_index in PMI_A_base._stat_axis.values.tolist():\n",
    "        for term_index in range(0, len(A_base_word)):\n",
    "            PMI_A_base.iloc[story_index,term_index] = PMI_A_base.iloc[story_index,term_index]* BoW_A_test.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "    PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_BoW_'+str(nums)+'.V_cat_no.'+'test'+'.csv',index = 0)\n",
    "    PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_BoW_'+str(nums)+'.A_cat_no.'+'test'+'.csv',index = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Done')\n",
    "print('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "                  \n",
    "#         for term in V_base_word:\n",
    "        \n",
    "\n",
    "#     for word_index in range(0,len(V_base_word)):\n",
    "#         for story_index in range(0,len(TF_IDF_V_train)):\n",
    "#             if V_base_word[word_index] in TF_IDF_V_train.loc[story_index]:\n",
    "#                 PMI_V_base.iloc[story_index,word_index] = PMI_V_base.iloc[story_index,word_index]*TF_IDF_V_train.iloc[story_index,word_index]\n",
    "#             else:\n",
    "#                 PMI_V_base.iloc[story_index,word_index] = 0\n",
    "\n",
    "#         for word_index in range(0,len(A_base_word)):\n",
    "#             for story_index in range(0,len(TF_IDF_A_train)):\n",
    "#                 if A_base_word[word_index] in TF_IDF_V_train.loc[story_index]:\n",
    "#                     PMI_A_base.iloc[story_index,word_index] = PMI_A_base.iloc[story_index,word_index]*TF_IDF_A_train.iloc[story_index,word_index]\n",
    "#                 else:\n",
    "#                     PMI_A_base.iloc[story_index,word_index] = 0\n",
    "\n",
    "#         PMI_V_base[0:87].to_csv('ComParE2020_USOMS-e.PMI_base_'+str(nums)+'.V_cat_no.'+'train'+'.csv',index = 0)\n",
    "#         PMI_A_base[0:87].to_csv('ComParE2020_USOMS-e.PMI_base_'+str(nums)+'.A_cat_no.'+'train'+'.csv',index = 0)\n",
    "#         PMI_V_base[87:175].to_csv('ComParE2020_USOMS-e.PMI_base_'+str(nums)+'.V_cat_no.'+'devel'+'.csv',index = 0)\n",
    "#         PMI_A_base[87:175].to_csv('ComParE2020_USOMS-e.PMI_base_'+str(nums)+'.A_cat_no.'+'devel'+'.csv',index = 0)\n",
    "\n",
    "#         PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.V_cat_no.'+'train'+'.csv',index = 0)\n",
    "#         PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.A_cat_no.'+'train'+'.csv',index = 0)\n",
    "\n",
    "#         PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_devel)))\n",
    "#         PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_devel)))\n",
    "\n",
    "#         for word_index in range(0,len(V_base_word)):\n",
    "#             for story_index in range(0,len(preprocessed_devel)):\n",
    "#                 if V_base_word[word_index] in preprocessed_devel[story_index]:\n",
    "#                     PMI_V_base.iloc[story_index,word_index] = PMI_V_base.iloc[story_index,word_index]*1\n",
    "#                 else:\n",
    "#                     PMI_V_base.iloc[story_index,word_index] = PMI_V_base.iloc[story_index,word_index]*0\n",
    "\n",
    "#         for word_index in range(0,len(A_base_word)):\n",
    "#             for story_index in range(0,len(preprocessed_devel)):\n",
    "#                 if A_base_word[word_index] in preprocessed_devel[story_index]:\n",
    "#                     PMI_A_base.iloc[story_index,word_index] = PMI_A_base.iloc[story_index,word_index]*1\n",
    "#                 else:\n",
    "#                     PMI_A_base.iloc[story_index,word_index] = PMI_A_base.iloc[story_index,word_index]*0\n",
    "\n",
    "#         PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_'+str(nums)+'.V_cat_no.'+'devel'+'.csv',index = 0)\n",
    "#         PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_'+str(nums)+'.A_cat_no.'+'devel'+'.csv',index = 0)\n",
    "\n",
    "\n",
    "#         PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_test)))\n",
    "#         PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_test)))\n",
    "\n",
    "#         for word_index in range(0,len(V_base_word)):\n",
    "#             for story_index in range(0,len(preprocessed_test)):\n",
    "#                 if V_base_word[word_index] in preprocessed_test[story_index]:\n",
    "#                     PMI_V_base.iloc[story_index,word_index] = PMI_V_base.iloc[story_index,word_index]*1\n",
    "#                 else:\n",
    "#                     PMI_V_base.iloc[story_index,word_index] = PMI_V_base.iloc[story_index,word_index]*0\n",
    "\n",
    "#         for word_index in range(0,len(A_base_word)):\n",
    "#             for story_index in range(0,len(preprocessed_test)):\n",
    "#                 if A_base_word[word_index] in preprocessed_test[story_index]:\n",
    "#                     PMI_A_base.iloc[story_index,word_index] = PMI_A_base.iloc[story_index,word_index]*1\n",
    "#                 else:\n",
    "#                     PMI_A_base.iloc[story_index,word_index] = PMI_A_base.iloc[story_index,word_index]*0\n",
    "\n",
    "#         PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_'+str(nums)+'.V_cat_no.'+'test'+'.csv',index = 0)\n",
    "#         PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_'+str(nums)+'.A_cat_no.'+'test'+'.csv',index = 0)\n",
    "\n",
    "#         print('Done')\n",
    "#     print('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMI_V_table = pd.read_csv('PMI_V_'+'train'+'.csv',index_col=0)\n",
    "# PMI_A_table = pd.read_csv('PMI_A_'+'train'+'.csv',index_col=0)\n",
    "\n",
    "# # PMI_V_table.columns = uniques_word_list\n",
    "# # PMI_A_table.columns = uniques_word_list\n",
    "# # PMI_V_table.index = label_list\n",
    "# # PMI_A_table.index = label_list\n",
    "\n",
    "# PMI_V_L_list = list(PMI_V_table.loc[0].values)\n",
    "# PMI_V_M_list = list(PMI_V_table.loc[1].values)\n",
    "# PMI_V_H_list = list(PMI_V_table.loc[2].values)\n",
    "\n",
    "# PMI_V_L = dict(zip(uniques_word_list,PMI_V_L_list))\n",
    "# PMI_V_M = dict(zip(uniques_word_list,PMI_V_M_list))\n",
    "# PMI_V_H = dict(zip(uniques_word_list,PMI_V_H_list))\n",
    "\n",
    "# sorted_PMI_V_L = sorted(PMI_V_L.items(),key = operator.itemgetter(1),reverse=True)\n",
    "# sorted_PMI_V_M = sorted(PMI_V_M.items(),key = operator.itemgetter(1),reverse=True)\n",
    "# sorted_PMI_V_H = sorted(PMI_V_H.items(),key = operator.itemgetter(1),reverse=True)\n",
    "\n",
    "\n",
    "# PMI_A_L_list = list(PMI_A_table.loc[0].values)\n",
    "# PMI_A_M_list = list(PMI_A_table.loc[1].values)\n",
    "# PMI_A_H_list = list(PMI_A_table.loc[2].values)\n",
    "\n",
    "# PMI_A_L = dict(zip(uniques_word_list,PMI_A_L_list))\n",
    "# PMI_A_M = dict(zip(uniques_word_list,PMI_A_M_list))\n",
    "# PMI_A_H = dict(zip(uniques_word_list,PMI_A_H_list))\n",
    "\n",
    "# sorted_PMI_A_L = sorted(PMI_A_L.items(),key = operator.itemgetter(1),reverse=True)\n",
    "# sorted_PMI_A_M = sorted(PMI_A_M.items(),key = operator.itemgetter(1),reverse=True)\n",
    "# sorted_PMI_A_H = sorted(PMI_A_H.items(),key = operator.itemgetter(1),reverse=True)\n",
    "\n",
    "# # TF_IDF_V_train = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.V_cat_no.train.csv')\n",
    "# # TF_IDF_V_devel = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.V_cat_no.devel.csv')\n",
    "# # TF_IDF_V_test = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.V_cat_no.test.csv')\n",
    "\n",
    "# # TF_IDF_A_train = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.A_cat_no.train.csv')\n",
    "# # TF_IDF_A_devel = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.A_cat_no.devel.csv')\n",
    "# # TF_IDF_A_test = pd.read_csv('Train_only/ComParE2020_USOMS-e.TF_IDF.A_cat_no.test.csv')\n",
    "\n",
    "# BoW_V_train = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.V_cat_no.train.csv')\n",
    "# BoW_V_devel = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.V_cat_no.devel.csv')\n",
    "# BoW_V_test = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.V_cat_no.test.csv')\n",
    "\n",
    "# BoW_A_train = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.A_cat_no.train.csv')\n",
    "# BoW_A_devel = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.A_cat_no.devel.csv')\n",
    "# BoW_A_test = pd.read_csv('Train_only/ComParE2020_USOMS-e.BoW.A_cat_no.test.csv')\n",
    "\n",
    "# number = [600,800,1000,1200,1500,1800]\n",
    "# # number = [1000]\n",
    "\n",
    "# for nums in number:\n",
    "#     V_L_base = sorted_PMI_V_L[0:nums]\n",
    "#     V_M_base = sorted_PMI_V_M[0:nums]\n",
    "#     V_H_base = sorted_PMI_V_H[0:nums]\n",
    "#     V_L_base_word = [i[0] for i in V_L_base]\n",
    "#     V_L_base_value = [i[1] for i in V_L_base]\n",
    "#     V_M_base_word = [i[0] for i in V_L_base]\n",
    "#     V_M_base_value = [i[1] for i in V_L_base]\n",
    "#     V_H_base_word = [i[0] for i in V_L_base]\n",
    "#     V_H_base_value = [i[1] for i in V_L_base]\n",
    "#     V_base_value = V_L_base_value+V_M_base_value+V_H_base_value\n",
    "#     V_base_word = V_L_base_word+V_M_base_word+V_H_base_word\n",
    "    \n",
    "#     A_L_base = sorted_PMI_A_L[0:nums]\n",
    "#     A_M_base = sorted_PMI_A_M[0:nums]\n",
    "#     A_H_base = sorted_PMI_A_H[0:nums]\n",
    "#     A_L_base_word = [i[0] for i in A_L_base]\n",
    "#     A_L_base_value = [i[1] for i in A_L_base]\n",
    "#     A_M_base_word = [i[0] for i in A_L_base]\n",
    "#     A_M_base_value = [i[1] for i in A_L_base]\n",
    "#     A_H_base_word = [i[0] for i in A_L_base]\n",
    "#     A_H_base_value = [i[1] for i in A_L_base]\n",
    "#     A_base_value = A_L_base_value+A_M_base_value+A_H_base_value\n",
    "#     A_base_word = A_L_base_word+A_M_base_word+A_H_base_word\n",
    "\n",
    "\n",
    "#     PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_train)))\n",
    "#     PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_train)))\n",
    "#     for story_index in PMI_V_base._stat_axis.values.tolist():\n",
    "#         for term_index in range(0, len(V_base_word)):\n",
    "#             PMI_V_base.iloc[story_index,term_index] = PMI_V_base.iloc[story_index,term_index]* TF_IDF_V_train.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "#     for story_index in PMI_A_base._stat_axis.values.tolist():\n",
    "#         for term_index in range(0, len(A_base_word)):\n",
    "#             PMI_A_base.iloc[story_index,term_index] = PMI_A_base.iloc[story_index,term_index]* TF_IDF_A_train.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "#     PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.V_cat_no.'+'train'+'.csv',index = 0)\n",
    "#     PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.A_cat_no.'+'train'+'.csv',index = 0)\n",
    "    \n",
    "    \n",
    "#     PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_devel)))\n",
    "#     PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_devel)))\n",
    "#     for story_index in PMI_V_base._stat_axis.values.tolist():\n",
    "#         for term_index in range(0, len(V_base_word)):\n",
    "#             PMI_V_base.iloc[story_index,term_index] = PMI_V_base.iloc[story_index,term_index]* TF_IDF_V_devel.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "#     for story_index in PMI_A_base._stat_axis.values.tolist():\n",
    "#         for term_index in range(0, len(A_base_word)):\n",
    "#             PMI_A_base.iloc[story_index,term_index] = PMI_A_base.iloc[story_index,term_index]* TF_IDF_A_devel.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "#     PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.V_cat_no.'+'devel'+'.csv',index = 0)\n",
    "#     PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.A_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    \n",
    "    \n",
    "#     PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_test)))\n",
    "#     PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_test)))\n",
    "#     for story_index in PMI_V_base._stat_axis.values.tolist():\n",
    "#         for term_index in range(0, len(V_base_word)):\n",
    "#             PMI_V_base.iloc[story_index,term_index] = PMI_V_base.iloc[story_index,term_index]* TF_IDF_V_test.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "#     for story_index in PMI_A_base._stat_axis.values.tolist():\n",
    "#         for term_index in range(0, len(A_base_word)):\n",
    "#             PMI_A_base.iloc[story_index,term_index] = PMI_A_base.iloc[story_index,term_index]* TF_IDF_A_test.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "#     PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.V_cat_no.'+'test'+'.csv',index = 0)\n",
    "#     PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_TF_IDF_'+str(nums)+'.A_cat_no.'+'test'+'.csv',index = 0)\n",
    "\n",
    "\n",
    "\n",
    "#     PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_train)))\n",
    "#     PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_train)))\n",
    "#     for story_index in PMI_V_base._stat_axis.values.tolist():\n",
    "#         for term_index in range(0, len(V_base_word)):\n",
    "#             PMI_V_base.iloc[story_index,term_index] = PMI_V_base.iloc[story_index,term_index]* BoW_V_train.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "#     for story_index in PMI_A_base._stat_axis.values.tolist():\n",
    "#         for term_index in range(0, len(A_base_word)):\n",
    "#             PMI_A_base.iloc[story_index,term_index] = PMI_A_base.iloc[story_index,term_index]* BoW_A_train.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "#     PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_BoW_'+str(nums)+'.V_cat_no.'+'train'+'.csv',index = 0)\n",
    "#     PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_BoW_'+str(nums)+'.A_cat_no.'+'train'+'.csv',index = 0)\n",
    "    \n",
    "    \n",
    "#     PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_devel)))\n",
    "#     PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_devel)))\n",
    "#     for story_index in PMI_V_base._stat_axis.values.tolist():\n",
    "#         for term_index in range(0, len(V_base_word)):\n",
    "#             PMI_V_base.iloc[story_index,term_index] = PMI_V_base.iloc[story_index,term_index]* BoW_V_devel.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "#     for story_index in PMI_A_base._stat_axis.values.tolist():\n",
    "#         for term_index in range(0, len(A_base_word)):\n",
    "#             PMI_A_base.iloc[story_index,term_index] = PMI_A_base.iloc[story_index,term_index]* BoW_A_devel.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "#     PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_BoW_'+str(nums)+'.V_cat_no.'+'devel'+'.csv',index = 0)\n",
    "#     PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_BoW_'+str(nums)+'.A_cat_no.'+'devel'+'.csv',index = 0)\n",
    "    \n",
    "    \n",
    "#     PMI_V_base = pd.DataFrame(pd.DataFrame([V_base_value]*len(preprocessed_test)))\n",
    "#     PMI_A_base = pd.DataFrame(pd.DataFrame([A_base_value]*len(preprocessed_test)))\n",
    "#     for story_index in PMI_V_base._stat_axis.values.tolist():\n",
    "#         for term_index in range(0, len(V_base_word)):\n",
    "#             PMI_V_base.iloc[story_index,term_index] = PMI_V_base.iloc[story_index,term_index]* BoW_V_test.loc[story_index, V_base_word[term_index]]\n",
    "            \n",
    "#     for story_index in PMI_A_base._stat_axis.values.tolist():\n",
    "#         for term_index in range(0, len(A_base_word)):\n",
    "#             PMI_A_base.iloc[story_index,term_index] = PMI_A_base.iloc[story_index,term_index]* BoW_A_test.loc[story_index, A_base_word[term_index]]\n",
    "            \n",
    "#     PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base_BoW_'+str(nums)+'.V_cat_no.'+'test'+'.csv',index = 0)\n",
    "#     PMI_A_base.to_csv('ComParE2020_USOMS-e.PMI_base_BoW_'+str(nums)+'.A_cat_no.'+'test'+'.csv',index = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     print('Done')\n",
    "# print('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word_index in range(0,len(V_base_word)):\n",
    "#     for story_index in range(0,len(preprocessed_train)):\n",
    "#         if V_base_word[word_index] in preprocessed_train[story_index]:\n",
    "#             PMI_V_base.iloc[story_index,word_index] = PMI_V_base.iloc[story_index,word_index]*1\n",
    "#         else:\n",
    "#             PMI_V_base.iloc[story_index,word_index] = PMI_V_base.iloc[story_index,word_index]*0\n",
    "            \n",
    "# for word_index in range(0,len(A_base_word)):\n",
    "#     for story_index in range(0,len(preprocessed_train)):\n",
    "#         if A_base_word[word_index] in preprocessed_train[story_index]:\n",
    "#             PMI_A_base.iloc[story_index,word_index] = PMI_A_base.iloc[story_index,word_index]*1\n",
    "#         else:\n",
    "#             PMI_A_base.iloc[story_index,word_index] = PMI_A_base.iloc[story_index,word_index]*0\n",
    "# #             df.replace({'A': 0, 'B': 5}, 100)\n",
    "# # for index in\n",
    "# # def PMI():\n",
    "# PMI_V_base\n",
    "# PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base'+number+'.V_cat_no.'+'train'+'.csv',index = 0)\n",
    "# PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_base'+number+'.A_cat_no.'+'train'+'.csv',index = 0)\n",
    "# # PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_V_base.V_cat_no.'+'devel'+'.csv',index = 0)\n",
    "# # PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_A_base.A_cat_no.'+'devel'+'.csv',index = 0)\n",
    "# # PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_V_base.V_cat_no.'+'test'+'.csv',index = 0)\n",
    "# # PMI_V_base.to_csv('ComParE2020_USOMS-e.PMI_A_base.A_cat_no.'+'test'+'.csv',index = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
